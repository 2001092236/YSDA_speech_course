{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WBhekFQP1X9t"
      },
      "source": [
        "# Speech Recognition I"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qHX36qdCXdqb"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SuQxF7zAmq4J"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "mkdir -p week_04_asr_files\n",
        "wget -O week_04_asr_files/test_matrix.txt -q https://raw.githubusercontent.com/yandexdataschool/speech_course/main/week_04_asr/test_matrix.txt\n",
        "wget -O week_04_asr_files/alphas.txt -q https://raw.githubusercontent.com/yandexdataschool/speech_course/main/week_04_asr/alphas.txt\n",
        "wget -O week_04_asr_files/betas.txt -q https://raw.githubusercontent.com/yandexdataschool/speech_course/main/week_04_asr/betas.txt\n",
        "wget -O week_04_asr_files/soft_alignment.txt -q https://raw.githubusercontent.com/yandexdataschool/speech_course/main/week_04_asr/soft_alignment.txt\n",
        "wget -O week_04_asr_files/h035_Bar_LargeSportsBar_5.wav -q https://raw.githubusercontent.com/yandexdataschool/speech_course/main/week_04_asr/h035_Bar_LargeSportsBar_5.wav"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GX7sUQYrXhoE"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import os\n",
        "import string\n",
        "\n",
        "from typing import List\n",
        "\n",
        "import editdistance\n",
        "import librosa\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torchaudio\n",
        "\n",
        "from IPython import display\n",
        "from matplotlib import pyplot as plt\n",
        "from torch import distributions\n",
        "from torch import nn\n",
        "\n",
        "week_04_asr_files = 'week_04_asr_files'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TW3gJ1Zu3bgR"
      },
      "source": [
        "## Metrics\n",
        "### WER (Word Error Rate)\n",
        "WER measures the difference between the reference transcript and the output transcript in terms of words. It is calculated as the minimum number of insertions, deletions, and substitutions required to transform the output into the reference, divided by the total number of words in the reference.\n",
        "\n",
        "### CER (Character Error Rate)\n",
        "CER, similar to WER, measures the error rate but at the character level. It calculates the minimum number of insertions, deletions, and substitutions required to transform the output into the reference, divided by the total number of characters in the reference.\n",
        "\n",
        "### Implement WER and CER Calculation\n",
        "Your task is to implement functions to calculate WER and CER using the editdistance library. Assume that both the reference and output transcripts are strings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0pHHjIwd5BNN"
      },
      "outputs": [],
      "source": [
        "def calculate_wer(reference, hypothesis):\n",
        "    \"\"\"Calculates the Word Error Rate (WER).\n",
        "\n",
        "    WER measures the difference between the reference transcript and the output\n",
        "    transcript in terms of words. It is calculated as the minimum number of\n",
        "    insertions, deletions, and substitutions required to transform the output\n",
        "    into the reference, divided by the total number of words in the reference.\n",
        "\n",
        "    Args:\n",
        "    reference: The reference transcript.\n",
        "    hypothesis: The output transcript.\n",
        "\n",
        "    Returns:\n",
        "    The WER as a float.\n",
        "    \"\"\"\n",
        "    # YOUR CODE\n",
        "\n",
        "    return wer\n",
        "\n",
        "\n",
        "def calculate_cer(reference, hypothesis):\n",
        "    \"\"\"Calculates the Character Error Rate (CER).\n",
        "\n",
        "    CER, similar to WER, measures the error rate but at the character level.\n",
        "    It calculates the minimum number of insertions, deletions, and substitutions\n",
        "    required to transform the output into the reference, divided by the total\n",
        "    number of characters in the reference.\n",
        "\n",
        "    Args:\n",
        "    reference: The reference transcript.\n",
        "    hypothesis: The output transcript.\n",
        "\n",
        "    Returns:\n",
        "    The CER as a float.\n",
        "    \"\"\"\n",
        "    # YOUR CODE\n",
        "\n",
        "    return cer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MHb6v8aF1Nu8"
      },
      "outputs": [],
      "source": [
        "assert calculate_wer('hello world', 'hello world') == 0.0\n",
        "assert calculate_wer('hello world', 'hello') == 1 / 2\n",
        "assert calculate_wer('hello world', '') == 1.0\n",
        "assert calculate_wer('hello world', 'hello hello hello hello') == 3 / 2\n",
        "\n",
        "assert calculate_cer('hello', 'hello') == 0.0\n",
        "assert calculate_cer('hello', 'hell') == 1 / 5\n",
        "assert calculate_cer('hello', 'he') == 3 / 5\n",
        "assert calculate_cer('hello', 'h') == 4 / 5\n",
        "assert calculate_cer('hello', '') == 1.0\n",
        "assert calculate_cer('hello', 'hhhhelloooo') == 6 / 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLFByP7t9LZl"
      },
      "source": [
        "## Sound Augmentations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kR9MHScsE-x2"
      },
      "outputs": [],
      "source": [
        "def visualize_audio(wav: torch.Tensor, sr: int = 16000):\n",
        "    plt.figure(figsize=(12, 4))\n",
        "    plt.plot(wav, alpha=.7, c='blue')\n",
        "    plt.grid()\n",
        "    plt.xlabel('Time', size=10)\n",
        "    plt.ylabel('Amplitude', size=10)\n",
        "    plt.show()\n",
        "    display.display(display.Audio(wav, rate=sr, normalize=False))\n",
        "\n",
        "wav, sr = librosa.load(librosa.ex('brahms'), duration=10)\n",
        "wav = torch.from_numpy(wav)\n",
        "if wav.dim() == 2:\n",
        "    wav = wav.mean(dim=0)\n",
        "visualize_audio(wav, sr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xX4Uc5B9EvQS"
      },
      "source": [
        "### Gaussian Noise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1rJ9YpgiExBf"
      },
      "outputs": [],
      "source": [
        "noiser = distributions.Normal(0, 0.05)\n",
        "augumented_wav = wav + noiser.sample(wav.size())\n",
        "visualize_audio(augumented_wav, sr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hLbWlecgEvLV"
      },
      "source": [
        "### Time Stretching\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "syXTr9P3EzaH"
      },
      "outputs": [],
      "source": [
        "augumented_wav = librosa.effects.time_stretch(wav.numpy().squeeze(), rate=2.0)\n",
        "augumented_wav = torch.from_numpy(augumented_wav)\n",
        "visualize_audio(augumented_wav, sr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m2JTNHA2EvG4"
      },
      "source": [
        "### Pitch Shifting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8194AHFHEy_A"
      },
      "outputs": [],
      "source": [
        "augumented_wav = librosa.effects.pitch_shift(wav.numpy().squeeze(), sr=sr, n_steps=-5)\n",
        "augumented_wav = torch.from_numpy(augumented_wav)\n",
        "visualize_audio(augumented_wav, sr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I0K37rSaEvCZ"
      },
      "source": [
        "### Volume"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dr0GT0NJEzvW"
      },
      "outputs": [],
      "source": [
        "voler = torchaudio.transforms.Vol(gain=2.0, gain_type='amplitude')\n",
        "augumented_wav = voler(wav)\n",
        "visualize_audio(augumented_wav, sr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QCNIi1MaEu8J"
      },
      "source": [
        "### Impulse Response"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4_CDpAVt4g0"
      },
      "source": [
        "RIR datasets - https://github.com/RoyJames/room-impulse-responses  \n",
        "The example in the cell below is taken from the \"MID IR Survey\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Oj7fgq8XMRI"
      },
      "outputs": [],
      "source": [
        "rir, rir_sr = torchaudio.load(os.path.join(week_04_asr_files, 'h035_Bar_LargeSportsBar_5.wav'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jexmhfREGb6x"
      },
      "outputs": [],
      "source": [
        "def simulate(audio: torch.Tensor, rir: torch.Tensor):\n",
        "    left_pad = right_pad = rir.shape[-1] - 1\n",
        "\n",
        "    # Since torch.conv do cross-correlation (not convolution) we need to flip kernel\n",
        "    flipped_rir = rir.squeeze().flip(0)\n",
        "\n",
        "    audio = F.pad(audio, [left_pad, right_pad]).view(1, 1, -1)\n",
        "    convolved_audio = torch.conv1d(audio, flipped_rir.view(1, 1, -1)) \\\n",
        "        .squeeze()\n",
        "\n",
        "    # peak normalization\n",
        "    if convolved_audio.abs().max() > 1:\n",
        "        convolved_audio /= convolved_audio.abs().max()\n",
        "\n",
        "    return convolved_audio\n",
        "\n",
        "augumented_wav = simulate(wav, rir)\n",
        "visualize_audio(augumented_wav, sr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZzPVj5HE4lo"
      },
      "source": [
        "\n",
        "### Add Noise on Background"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JpLHgK9XE5CV"
      },
      "outputs": [],
      "source": [
        "filename = librosa.ex('trumpet')\n",
        "noise, _ = librosa.load(filename, sr=sr)\n",
        "visualize_audio(torch.from_numpy(noise), sr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4iFag9-TGetf"
      },
      "outputs": [],
      "source": [
        "noise_level = torch.Tensor([5])  # [0, 40]\n",
        "\n",
        "noise_energy = torch.norm(torch.from_numpy(noise))\n",
        "audio_energy = torch.norm(wav)\n",
        "\n",
        "alpha = (audio_energy / noise_energy) * torch.pow(10, -noise_level / 20)\n",
        "\n",
        "clipped_wav = wav[..., :noise.shape[0]]\n",
        "\n",
        "augumented_wav = clipped_wav + alpha * torch.from_numpy(noise)\n",
        "augumented_wav = torch.clamp(augumented_wav, -1, 1)\n",
        "\n",
        "visualize_audio(augumented_wav, sr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SD_qSnZsEs1x"
      },
      "source": [
        "### SpecAugment\n",
        "SpecAugment involves three types of augmentations: time warping, frequency masking, and time masking. Time warping warps the spectrogram along the time axis, while frequency masking and time masking involve masking random sections of the spectrogram in the frequency and time domains, respectively.\n",
        "\n",
        "https://arxiv.org/abs/1904.08779"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gXxvNTya9jqZ"
      },
      "outputs": [],
      "source": [
        "def spec_augment_masking(spectrogram, frequency_masking_factor, time_masking_factor):\n",
        "    \"\"\"SpecAugment involves three types of augmentations: time warping, frequency\n",
        "    masking, and time masking. Frequency masking and time masking involve masking random sections\n",
        "    of the spectrogram in the frequency and time domains, respectively.\n",
        "    Time warping is not implemented.\n",
        "\n",
        "    Args:\n",
        "    spectrogram: The spectrogram to augment.\n",
        "    frequency_masking_factor: The factor by which to mask the spectrogram in the\n",
        "        frequency domain.\n",
        "    time_masking_factor: The factor by which to mask the spectrogram in the\n",
        "        time domain.\n",
        "\n",
        "    Returns:\n",
        "    The augmented spectrogram.\n",
        "    \"\"\"\n",
        "    # Frequency masking\n",
        "    # YOUR CODE\n",
        "\n",
        "    # Time masking\n",
        "    # YOUR CODE\n",
        "\n",
        "    return spectrogram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dFt-N_t1JPRP"
      },
      "outputs": [],
      "source": [
        "mel_spectrogramer = torchaudio.transforms.MelSpectrogram(\n",
        "    sample_rate=sr,\n",
        "    n_fft=400,\n",
        "    win_length=400,\n",
        "    hop_length=200,\n",
        "    n_mels=80,\n",
        ")\n",
        "\n",
        "mel_spectrogram = mel_spectrogramer(wav)\n",
        "log_mel_spectrogram = torch.log(mel_spectrogram).squeeze()\n",
        "plt.figure(figsize=(20, 8))\n",
        "plt.imshow(log_mel_spectrogram)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dtTYBVsPIjfz"
      },
      "outputs": [],
      "source": [
        "augumented_log_mel_spectrogram = spec_augment_masking(log_mel_spectrogram, 0.3, 0.2)\n",
        "plt.figure(figsize=(20, 8))\n",
        "plt.imshow(augumented_log_mel_spectrogram)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lnUmkwSbY0Ho"
      },
      "source": [
        "## Lecture recap"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xTS5sHhoY0Ho"
      },
      "source": [
        "### Problem statement"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tb94FlS2Y0Hp"
      },
      "source": [
        "<p style=\"text-align:center;\"><img src=\"http://drive.google.com/uc?export=view&id=1FFGXZsCgy-uQfCBp7F4w1gaJbIGv6CV2\" height=\"200px\" width=\"700px\">  \n",
        "\n",
        "\n",
        "Define a modified label sequence $\\omega'_{1:2L + 1}$:\n",
        "- add blanks to the beginning and the end of the original label sequence $\\omega_{1:L}$\n",
        "- insert blanks between every pair of labels\n",
        "\n",
        "<p style=\"text-align:center;\"><img src=\"http://drive.google.com/uc?export=view&id=1CEhWtVYrSSkaRtEsJr5QwiH8lMaSQ_uN\" height=\"150px\" width=\"400px\">\n",
        "\n",
        "\n",
        "Define $\\alpha_t(s)$ as the probability of all paths of length $t$ which go through state $\\omega_s'$:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FUfXCzgBY0Hp"
      },
      "source": [
        "Denote a sequence of **acoustic features** or **observations** as\n",
        "\n",
        "$$\n",
        "    \\mathbf{X}_{1:T} = \\{x_1, \\ldots, x_T\\}\n",
        "$$\n",
        "\n",
        "Define a mapping $\\mathcal{M}$ between words $\\mathbf{w}$ and speech units $\\omega_{1:L}$:\n",
        "\n",
        "$$\n",
        "    \\{\\omega^{(q)}_{1:L_q}\\}^Q_{q = 1} = \\mathcal{M}(\\mathbf{w})\n",
        "$$\n",
        "\n",
        "$$\n",
        "    \\{\\mathbf{w}^{(p)}\\}^P_{p = 1} = \\mathcal{M}^{-1}(\\omega_{1:L})\n",
        "$$\n",
        "\n",
        "For some choices of speech units this mapping is not 1-to-1 ($Q > 1$, $P > 1$). A possible pair of text (green) and speech units (yellow):"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5qHamTYUY0Hq"
      },
      "source": [
        "<p style=\"text-align:center;\"><img src=\"http://drive.google.com/uc?export=view&id=1HWD_SFZzids3Nz67BK_NQ5awkw6yUvLo\" height=\"200px\" width=\"600px\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9AofS6uyY0Hq"
      },
      "source": [
        "Automated speech recognition (ASR) is a **discriminative** task $\\rightarrow$ \"Which sequence $\\mathbf{\\hat w}$ is likely given the audio?\":\n",
        "\n",
        "$$\n",
        "    \\mathbf{\\hat w} = \\mathcal{M}^{-1}(\\hat \\omega_{1:L}), \\quad \\hat \\omega_{1:L} = \\arg \\max_{\\hat \\omega_{1: L}} P(\\hat \\omega_{1:L} | \\mathbf{X}_{1: T}; \\theta),\n",
        "$$\n",
        "\n",
        "where $\\theta$ denotes the parameters of the model we are building to solve the problem."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-7IK0-TY0Hr"
      },
      "source": [
        "### Discriminative state-space models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1hFDyco4Y0Hr"
      },
      "source": [
        "How feature vectors $\\mathbf{X}_{1: T}$ and speech units $\\omega_{1:L}$ relate or **align** to each other? Two common approaches to constructing models which can align:\n",
        "- state-space models\n",
        "- neural attention mechanisms\n",
        "\n",
        "State-space models represent the space of various alignments in the form of a table (called **trellis**), the rows of which correspond to phonemes, and the columns are observed variables. One alignment is the path in this table from the upper left corner to the lower right.\n",
        "\n",
        "<p style=\"text-align:center;\"><img src=\"http://drive.google.com/uc?export=view&id=1npycuLvYq_-3p_xd6bouR21tfVeOvMUd\" height=\"300px\" width=\"600px\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Txs7XA-2Y0Hs"
      },
      "source": [
        "Denote a set of all paths in trellis that map onto the phoneme sequence $\\omega_{1:L}$ as ${A}(\\omega_{1:L})$, and let $\\pi_{1:T} \\in {A}(\\omega_{1:L})$ be an element of this set. Then a discriminative state-space system models $P(\\omega_{1:L} | \\mathbf{X}_{1: T}; \\theta)$ as\n",
        "\n",
        "$$\n",
        "    P(\\omega_{1:L} | \\mathbf{X}_{1: T}; \\theta) = \\sum_{\\pi_{1:T} \\in {A}(\\omega_{1:L})} P(\\pi_{1:T} | \\mathbf{X}_{1:T}; \\theta)\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmxvKSgKY0Hs"
      },
      "source": [
        "Imagine that we have a recurrent neural network parametrized with $\\theta$. The network outputs a distribution $P(z_t|x_t; \\theta)$ over possible speech units $\\omega$ for each frame $x_t$:\n",
        "\n",
        "<p style=\"text-align:center;\"><img src=\"http://drive.google.com/uc?export=view&id=153E-ailMiLPg3joPSx016lGv6S4vXVD2\" height=\"300px\" width=\"550px\">\n",
        "\n",
        "CTC is a discriminative state-space model defined as:\n",
        "    \n",
        "$$\n",
        "    P(\\omega_{1:L} | \\mathbf{X}_{1: T}; \\theta) = \\sum_{\\pi_{1:T} \\in {A}(\\omega_{1:L})} \\prod_{t = 1}^T P(z_t = \\pi_t| x_t; \\theta)\n",
        "$$\n",
        "    \n",
        "- CTC assumes all states conditionally independent\n",
        "- Alignment free -- does not need prior alignment for training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mYKuPLiqV5hS"
      },
      "source": [
        "## Homework: CTC Forward-Backward Algorithm (10 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g8mSKTb_r0m3"
      },
      "source": [
        "- (4 points) Implement a Forward Algorithm\n",
        "- (4 points) Implement a Backward  \n",
        "- (2 points) Implement soft alignment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D18HUJoPXQVs"
      },
      "outputs": [],
      "source": [
        "# Helper functions\n",
        "BLANK_SYMBOL = \"_\"\n",
        "\n",
        "class Tokenizer:\n",
        "    \"\"\"\n",
        "    Maps characters to integers and vice versa\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        self.char_map = {}\n",
        "        self.index_map = {}\n",
        "        for i, ch in enumerate([\"'\", \" \"] + list(string.ascii_lowercase) + [BLANK_SYMBOL]):\n",
        "            self.char_map[ch] = i\n",
        "            self.index_map[i] = ch\n",
        "\n",
        "    def text_to_indices(self, text: str) -> List[int]:\n",
        "        return [self.char_map[ch] for ch in text]\n",
        "\n",
        "    def indices_to_text(self, labels: List[int]) -> str:\n",
        "        return \"\".join([self.index_map[i] for i in labels])\n",
        "\n",
        "    def get_symbol_index(self, sym: str) -> int:\n",
        "        return self.char_map[sym]\n",
        "\n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "\n",
        "NEG_INF = -float(\"inf\")\n",
        "\n",
        "\n",
        "def logsumexp(*args) -> float:\n",
        "    \"\"\"\n",
        "    Log-sum-exp trick for log-domain calculations\n",
        "    See for details: https://en.wikipedia.org/wiki/LogSumExp\n",
        "    \"\"\"\n",
        "    if all(a == NEG_INF for a in args):\n",
        "        return NEG_INF\n",
        "    a_max = max(args)\n",
        "    lsp = math.log(sum(math.exp(a - a_max) for a in args))\n",
        "    return a_max + lsp\n",
        "\n",
        "\n",
        "def modify_sequence(sequence: List[int], blank_idx: int) -> List[int]:\n",
        "    \"\"\"\n",
        "    Modifies sequence which with START, END blanks and between each character\n",
        "    \"\"\"\n",
        "    modified_sequence = []\n",
        "\n",
        "    for idx in sequence:\n",
        "        modified_sequence += [blank_idx, idx]\n",
        "\n",
        "    modified_sequence.append(blank_idx)\n",
        "    return modified_sequence\n",
        "\n",
        "# Load test input and output data\n",
        "matrix = np.loadtxt(os.path.join(week_04_asr_files, 'test_matrix.txt'))\n",
        "labels_indices = tokenizer.text_to_indices('there se ms no good reason for believing that twillc ange')\n",
        "ref_alphas = np.loadtxt(os.path.join(week_04_asr_files, 'alphas.txt'))\n",
        "ref_betas = np.loadtxt(os.path.join(week_04_asr_files, 'betas.txt'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ZNqkmCpqOqc"
      },
      "source": [
        "### Definitions reminder\n",
        "$X_{1:T}$ - input sequence (acoustic frames)  \n",
        "$\\omega_{1:L}$ - target sequence (text tokens)  \n",
        "$\\omega_{1:L}'$ - target sequence augmented with $\\epsilon$ token  \n",
        "$\\pi_{1:T}$ - one of the alignment sequences for $\\omega_{1:L}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BpGdNVM5V_Ir"
      },
      "source": [
        "### Forward Algorithm (4 points)\n",
        "\n",
        "$$\n",
        "    \\alpha_t(s) = P(\\omega_{1:s/2}, \\pi_t = \\omega_s' | \\mathbf{X}_{1:T}, \\theta) = \\sum_{\\pi_{1:t - 1} \\in {A}(\\omega_{1:s/2}), \\, \\pi_t = \\omega_s'}  P(\\pi_{1:t} | \\mathbf{X}_{1:T}, \\theta)\n",
        "$$\n",
        "\n",
        "Note that despite the fact that we have moved to the extended sequence $\\omega'$, we are still interested in maximizing the probability of alignments to the original sequence. And step $s$ in the new sequence corresponds to step $s/2$ in the old sequence (rounded to the bottom).\n",
        "\n",
        "The CTC forward algorithm recursively computes the forward variable $\\alpha_t(s)$.\n",
        "\n",
        "<p style=\"text-align:center;\"><img src=\"http://drive.google.com/uc?export=view&id=1QaW0mJ9c3Z0KJVk3pUSyC_kS_pFC_QxS\" height=\"400px\" width=\"600px\">  \n",
        "\n",
        "\n",
        "**Initialization.** We allow all prefixes to start with either a blank ($\\epsilon$) or the first symbol in $\\omega_{1:L}$. Also note that $\\alpha_t(s) = 0,\\ \\forall s < (2L + 1) - 2(T - t) - 1$, because these variables correspond to states for which there are not enough time-steps left to complete the sequence.\n",
        "\n",
        "This gives us the following rules for initialization:\n",
        "\n",
        "$$\n",
        "  \\begin{aligned}\n",
        "    &\\alpha_t(0) = 0, \\forall t & \\\\\n",
        "    &\\alpha_1(1) = P(z_1 = \\epsilon | \\mathbf{X}_{1:T}), &\\\\\n",
        "    &\\alpha_1(2) = P(z_1 = \\omega^{'}_2 | \\mathbf{X}_{1:T}), &\\\\\n",
        "    &\\alpha_1(s) = 0,\\ \\forall s > 2 &\\\\\n",
        "    &\\alpha_t(s) = 0,\\ \\forall s < (2L + 1) - 2(T - t) - 1 &  \\text{top right zeros}\\\\\n",
        "  \\end{aligned}\n",
        "$$\n",
        "\n",
        "**Recursion.**\n",
        "\n",
        "$$\n",
        "  \\begin{aligned}\n",
        "    &\\alpha_t(s) = \\left \\{\n",
        "  \\begin{aligned}\n",
        "    &\\big(\\alpha_{t-1}(s) + \\alpha_{t-1}(s-1) \\big) P(z_t = \\omega^{'}_s | \\mathbf{X}_{1:T}) & \\text{if}\\ \\omega_s^{'} = \\epsilon\\ \\text{or}\\\n",
        "    \\omega_s^{'} = \\omega_{s-2}^{'} \\\\\n",
        "    &\\big(\\alpha_{t-1}(s) + \\alpha_{t-1}(s-1) + \\alpha_{t-1}(s-2)\\big) P(z_t = \\omega^{'}_s | \\mathbf{X}_{1:T}) & \\text{otherwise}\\\\\n",
        "  \\end{aligned} \\right.\n",
        "  \\end{aligned}\n",
        "$$\n",
        "\n",
        "\n",
        "<p style=\"text-align:center;\"><img src=\"http://drive.google.com/uc?export=view&id=1Tre3oFHyjigpqG-GI1xVrOchZAMnRYBK\" height=\"250px\" width=\"650px\">\n",
        "\n",
        "Doing the computation in probability space can be numerically unstable, so you should do it in Log-Space using the\n",
        "provided logsumexp operation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fd0gmXhfYfUn"
      },
      "outputs": [],
      "source": [
        "def forward_algorithm(sequence: List[int], matrix: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    :param sequence: a string converted to an index array by Tokenizer\n",
        "    :param matrix: A matrix of shape (K, T) with probability distributions over phonemes at each moment of time.\n",
        "    :return: the result of the forward pass of shape (2 * len(sequence) + 1, T)\n",
        "    \"\"\"\n",
        "    # Turn probs into log-probs\n",
        "    matrix = np.log(matrix)\n",
        "\n",
        "    blank = tokenizer.get_symbol_index(BLANK_SYMBOL)\n",
        "    mod_sequence = modify_sequence(sequence, blank)\n",
        "\n",
        "    # Initialze\n",
        "    alphas = np.full([len(mod_sequence), matrix.shape[1]], NEG_INF)\n",
        "\n",
        "    for t in range(matrix.shape[1]):\n",
        "        for s in range(len(mod_sequence)):\n",
        "            # First Step\n",
        "            if t == 0:\n",
        "                ########################\n",
        "                # YOUR CODE HERE\n",
        "                ########################\n",
        "\n",
        "            # Upper diagonal zeros\n",
        "            elif # CONDITION\n",
        "                ########################\n",
        "                # YOUR CODE HERE\n",
        "                ########################\n",
        "            else:\n",
        "                # Need to do this stabily\n",
        "                if s == 0:\n",
        "                    ########################\n",
        "                    # YOUR CODE HERE\n",
        "                    ########################\n",
        "                elif s == 1:\n",
        "                    ########################\n",
        "                    # YOUR CODE HERE\n",
        "                    ########################\n",
        "                else:\n",
        "                    ########################\n",
        "                    # YOUR CODE HERE HINT - THERE IS ANOTHER IFELSE\n",
        "                    ########################\n",
        "    return alphas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's test the forward algorithm.  \n",
        "**These asserts are just helpers to discover a bug, and not real blockers. So if your code successfully runs the last assert from the soft alignment task you can ignore this batch of tests.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "alphas = forward_algorithm(labels_indices, matrix)\n",
        "\n",
        "incorrect_elements = np.nonzero(~np.isclose(ref_alphas, alphas))\n",
        "if incorrect_elements[1].shape[0]:\n",
        "    index = np.argmin(incorrect_elements[1])\n",
        "    incorrect_indices = (incorrect_elements[0][index], incorrect_elements[1][index])\n",
        "    print((\n",
        "        f'Leftmost incorrect time layer is t={incorrect_elements[1][index]}\\n'\n",
        "        f'Your alphas[{incorrect_indices[0]}, {incorrect_indices[1]}] = {alphas[incorrect_indices]:.5f}\\t'\n",
        "        f'Reference alphas[{incorrect_indices[0]}, {incorrect_indices[1]}] = {ref_alphas[incorrect_indices]:.5f}'\n",
        "    ))\n",
        "\n",
        "assert np.allclose(ref_alphas[:, 0], alphas[:, 0]), \"Bad initialization of the first layer of alphas (t = 0)\"\n",
        "assert np.allclose(ref_alphas[0, :], alphas[0, :]), \"Bad calculation of the first elemenent (probability of all-blank sequence '<blank>...<blank>') of the each layer\"\n",
        "assert np.allclose(ref_alphas[1, :], alphas[1, :]), \"Bad calculation of the second elemenent (probability of sequence '<blank>...<blank><first_token>') of the each layer\"\n",
        "assert np.allclose(ref_alphas[::2, :], alphas[::2, :]), \"Bad calculation of alphas for the blank tokens\"\n",
        "assert np.allclose(ref_alphas, alphas), \"Your alphas matrix is not close enough to the reference one\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGxYDyroWZgS"
      },
      "source": [
        "### Backward algorithm (4 points)\n",
        "\n",
        "Define $\\beta_t(s)$ as the probability of all valid alignments $\\omega'_{s:L}$ starting in state $\\omega_s'$:\n",
        "\n",
        "$$\n",
        "    \\beta_t(s) = P(\\omega_{s/2:L}, \\pi_t = \\omega'_s | \\mathbf{X}_{1:T}, \\theta) = \\sum_{\\pi_{t + 1:T} \\in \\mathcal{A}(\\omega_{s/2:L}), \\, \\pi_t = \\omega_s'} P(\\pi_{t + 1:T} | \\mathbf{X}_{1:T}, \\theta)\n",
        "$$\n",
        "\n",
        "The CTC backward algorithm recursively computes the backward variable $\\beta_t(s)$:\n",
        "\n",
        "<p style=\"text-align:center;\"><img src=\"http://drive.google.com/uc?export=view&id=11x3TGAzL2LWfO0ZKpPHegOvv8Iw6ZC0X\" height=\"400px\" width=\"600px\">\n",
        "\n",
        "\n",
        "\n",
        "The formulas for backward algorithm are as follows:\n",
        "\n",
        "$$\n",
        "  \\begin{aligned}\n",
        "    &\\beta_T(2L+1) = 1 &\\\\\n",
        "    &\\beta_T(2L) = 1 & \\\\\n",
        "    &\\beta_T(s) = 0, \\forall s < 2L &\\\\\n",
        "    &\\beta_t(s) = 0,\\ \\forall s > 2t &\\\\\n",
        "    &\\beta_t(2L+2) = 0,\\ \\forall t  & \\text{bottom left zeros} \\\\\n",
        "    &\\beta_t(s) = \\left \\{\n",
        "      \\begin{aligned}\n",
        "        &\\beta_{t+1}(s) P(z_{t + 1} = \\omega^{'}_s | \\mathbf{X}_{1:T}) + \\beta_{t+1}(s+1) P(z_{t + 1} = \\omega^{'}_{s + 1} | \\mathbf{X}_{1:T})  & \\text{if}\\ \\omega_s^{'} = \\epsilon\\ \\text{or}\\\n",
        "        \\omega_s^{'} = \\omega_{s+2}^{'} \\\\\n",
        "        &\\beta_{t+1}(s) P(z_{t + 1} = \\omega^{'}_s | \\mathbf{X}_{1:T}) + \\beta_{t+1}(s+1) P(z_{t + 1} = \\omega^{'}_{s + 1} | \\mathbf{X}_{1:T}) + \\beta_{t+1}(s+2) P(z_{t + 1} = \\omega^{'}_{s + 2} | \\mathbf{X}_{1:T}) & \\text{otherwise}\\\\\n",
        "      \\end{aligned}\\right.\n",
        "  \\end{aligned}\n",
        "$$\n",
        "\n",
        "<p style=\"text-align:center;\"><img src=\"http://drive.google.com/uc?export=view&id=1h7OBZZ02dwZ1mDhRYh7yTy7-UW4NmbXm\" height=\"250px\" width=\"650px\">\n",
        "\n",
        "Doing the computation in probability space can be numerically unstable, so you should do it in Log-Space using the\n",
        "provided logsumexp operation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y32s0jMfhm4x"
      },
      "outputs": [],
      "source": [
        "def backward_algorithm(sequence: List[int], matrix: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    :param sequence: a string converted to an index array by Tokenizer\n",
        "    :param matrix: A matrix of shape (K, T) with probability distributions over phonemes at each moment of time.\n",
        "    :return: the result of the backward pass of shape (2 * len(sequence) + 1, T)\n",
        "    \"\"\"\n",
        "    matrix = np.log(matrix)\n",
        "    blank = tokenizer.get_symbol_index(BLANK_SYMBOL)\n",
        "    mod_sequence = modify_sequence(sequence, blank)\n",
        "    betas = np.full([len(mod_sequence), matrix.shape[1]], NEG_INF)\n",
        "\n",
        "    for t in reversed(range(matrix.shape[1])):\n",
        "        for s in reversed(range(len(mod_sequence))):\n",
        "            # First Step\n",
        "            if t == matrix.shape[1] - 1:\n",
        "                ########################\n",
        "                # YOUR CODE HERE\n",
        "                ########################\n",
        "\n",
        "            # Lower Diagonal Zeros\n",
        "            elif # CONDITION\n",
        "                ########################\n",
        "                # YOUR CODE HERE\n",
        "                ########################\n",
        "            else:\n",
        "                if s == len(mod_sequence) - 1:\n",
        "                ########################\n",
        "                # YOUR CODE HERE\n",
        "                ########################\n",
        "                elif s == len(mod_sequence) - 2:\n",
        "                ########################\n",
        "                # YOUR CODE HERE\n",
        "                ########################\n",
        "                else:\n",
        "                    if mod_sequence[s] == blank or mod_sequence[s] == mod_sequence[s + 2]:\n",
        "                        ########################\n",
        "                        # YOUR CODE HERE\n",
        "                        ########################\n",
        "                    else:\n",
        "                        ########################\n",
        "                        # YOUR CODE HERE\n",
        "                        ########################\n",
        "    return betas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's test the backward algorithm.  \n",
        "**These asserts are just helpers to discover a bug, and not real blockers. So if your code successfully runs the last assert from the soft alignment task you can ignore this batch of tests.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "betas = backward_algorithm(labels_indices, matrix)\n",
        "\n",
        "incorrect_elements = np.nonzero(~np.isclose(ref_betas, betas))\n",
        "if incorrect_elements[1].shape[0]:\n",
        "    index = np.argmax(incorrect_elements[1])\n",
        "    incorrect_indices = (incorrect_elements[0][index], incorrect_elements[1][index])\n",
        "    print((\n",
        "        f'Rightmost incorrect time layer is t={incorrect_elements[1][index]}\\n'\n",
        "        f'Your betas[{incorrect_indices[0]}, {incorrect_indices[1]}] = {betas[incorrect_indices]:.5f}\\t'\n",
        "        f'Reference betas[{incorrect_indices[0]}, {incorrect_indices[1]}] = {ref_betas[incorrect_indices]:.5f}'\n",
        "    ))\n",
        "\n",
        "assert np.allclose(ref_betas[:, -1], betas[:, -1]), \"Bad initialization of the last layer of betas (t = matrix.shape[1] - 1)\"\n",
        "assert np.allclose(ref_betas[-1, :], betas[-1, :]), \"Bad calculation of the last elemenent (probability of all-blank sequence '<blank>...<blank>') of the each layer\"\n",
        "assert np.allclose(ref_betas[-2, :], betas[-2, :]), \"Bad calculation of the second-to-last elemenent (probability for the sequence '<last_token><blank>...<blank>') of the each layer\"\n",
        "assert np.allclose(ref_betas[::2, :], betas[::2, :]), \"Bad calculation of betas for the blank tokens\"\n",
        "assert np.allclose(ref_betas, betas), \"Your betas matrix is not close enough to the reference one\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxfIrL6gWffI"
      },
      "source": [
        "### Alignment and loss computation (2 points)\n",
        "\n",
        "Use your newfound knowledge of the CTC forward-backward algorithm to obtain a soft-alignment\n",
        "\n",
        "Remember, that the forward variable is computed as follows:\n",
        "\n",
        "The probability of all paths passing through a state $\\pi_t = \\omega_s'$ is the product of forward and backward variables:\n",
        "\n",
        "$$\n",
        "    \\alpha_t(s) \\beta_t(s) = \\sum_{\\pi_{1:T} \\in \\mathcal{A}(\\omega_{1:L}), \\,\\pi_t=\\omega_s'} P(\\pi_{1:T} | \\mathbf{X}_{1:T}, \\theta)\n",
        "$$\n",
        "\n",
        "Then, for any $t$, sum of all such products yields total probability:\n",
        "\n",
        "$$\n",
        "     \\sum_{s = 1}^{2 L + 1} \\alpha_t(s) \\beta_t(s) = P(\\omega_{1:L} | \\mathbf{X}_{1:T}, \\theta)\n",
        "$$\n",
        "\n",
        "We can also use normalized $\\alpha_t(s) \\beta_t(s)$ as a measure of **soft-alignment**:\n",
        "\n",
        "$$\n",
        "    \\text{align}_t(s) = \\frac{\\alpha_t(s) \\beta_t(s)}{\\sum_{s = 1}^{2 L + 1} \\alpha_t(s) \\beta_t(s)}\n",
        "$$\n",
        "\n",
        "You should get something like\n",
        "\n",
        "<p style=\"text-align:center;\"><img src=\"http://drive.google.com/uc?export=view&id=1HAIl9UPReiFQ7dNOZFGfvUWDurFDBZYM\" height=\"300px\" width=\"800px\">\n",
        "\n",
        "$$\n",
        "  \\text{align}_t(s) = \\frac{\\alpha_t(s)\\beta_t(s)}{\\sum_{s}\\alpha_t(s)\\beta_t(s)}\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bdLgoP6TWZLa"
      },
      "outputs": [],
      "source": [
        "def soft_alignment(labels_indices: List[int], matrix: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Returns the alignment coefficients for the input sequence\n",
        "    \"\"\"\n",
        "    alphas = forward_algorithm(labels_indices, matrix)\n",
        "    betas = backward_algorithm(labels_indices, matrix)\n",
        "\n",
        "    # Move from log space back to prob space\n",
        "    align = # YOUR CODE\n",
        "\n",
        "    # Normalize Alignment\n",
        "    align = # YOUR CODE\n",
        "\n",
        "    return align"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xQou5PWFV6A1"
      },
      "outputs": [],
      "source": [
        "matrix = np.loadtxt(os.path.join(week_04_asr_files, 'test_matrix.txt'))\n",
        "\n",
        "labels_indices = tokenizer.text_to_indices('there se ms no good reason for believing that twillc ange')\n",
        "\n",
        "align = soft_alignment(labels_indices, matrix)\n",
        "f, ax = plt.subplots(1, 2, dpi=75, figsize=(15, 5))\n",
        "\n",
        "im = ax[0].imshow(align, aspect='auto', interpolation='nearest')\n",
        "ax[0].set_title(\"Alignment\")\n",
        "ax[0].set_ylabel(\"Phonemes\")\n",
        "ax[0].set_xlabel(\"Time\")\n",
        "f.colorbar(im, ax=ax[0])\n",
        "\n",
        "im = ax[1].imshow(np.log(align), aspect='auto', interpolation='nearest')\n",
        "ax[1].set_title(\"Alignment in log scale\")\n",
        "ax[1].set_ylabel(\"Phonemes\")\n",
        "ax[1].set_xlabel(\"Time\")\n",
        "f.colorbar(im, ax=ax[1])\n",
        "\n",
        "plt.tight_layout()\n",
        "\n",
        "ref_align = np.loadtxt(os.path.join(week_04_asr_files, 'soft_alignment.txt'))\n",
        "assert np.allclose(ref_align, align)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
